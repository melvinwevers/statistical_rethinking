#+AUTHOR: Melvin Wevers
#+TITLE: 12. Multilevel Models
#+PROPERTY: header-args :session :results value :cache no :exports both



As models move from one cluster--individual, group, location--in the data to another,
estimating parameters for each cluster, they forget everything about the previous
clusters. 

We want models to learning simultaneously about each cluster while learning about the
population of clusters. 

Represent the population of cafes and learn about the population. Learn priors from data. 


*multilevel models* remember features of each cluster in the data as they learn about all
 of the clusters. 

Benefits of *multilevel models* include:
1. /Improved estimates for repeat sampling/. When more than one observation arises from the
   same individual, location, or time, then traditional, single-level models either
   maximally underfit or overfit the data.
2. /Improvied estiamtes for imbalance in sampling/. When some individuals, locations, or
   times are samples more than others, multilevels models automatically cope with
   differing uncertainty across these clusters. This prevents over-sampled clusters from
   unfairly dominating inference.
3. /Estimates of variation/.  If our research questions include variation among
   individuals or other groups within the data, then multilevel models are a big help,
   because they model variation explicitly. 
4. /Avoid averaging, retain variation/. Frequently, scholars pre-average some data to
   construct variables. This can be dangerous, because averaging removes variation, and
   there are also typically several different ways to perform the averaging. Averaging
   therefore constructs false confidence and introduces arbitrary data
   transformations. Multilevel models allow us to preserve the uncertainty and avoid data
   transformations. 

Costs of multilevel approach
1. Define the distributions from which the characteristics of the clusters
   arise. Conservative maximum entropy distributions are the solution
2. there are new estimation challenges > MCMC estimation
3. multilevel model can be hard to understand, because they make predictions at different
   levels of the data. 

* 12.1 Example: Multilevel tadpoles
#+BEGIN_SRC R :results output
library(rethinking)
data(reedfrogs)
d <- reedfrogs
str(d)

#+END_SRC

#+RESULTS:
: 
: 'data.frame':	48 obs. of  5 variables:
:  $ density : int  10 10 10 10 10 10 10 10 10 10 ...
:  $ pred    : Factor w/ 2 levels "no","pred": 1 1 1 1 1 1 1 1 2 2 ...
:  $ size    : Factor w/ 2 levels "big","small": 1 1 1 1 2 2 2 2 1 1 ...
:  $ surv    : int  9 10 7 10 9 9 10 9 4 9 ...
:  $ propsurv: num  0.9 1 0.7 1 0.9 0.9 1 0.9 0.4 0.9 ...

Multiple observations, the tadpoles in this case, are made within each cluster. 
A multilevel model, in which we simultaneously estimate both an intercept for each tank
and the variation among tanks, is what we want. this will be a *varying intercepts*
model. Varying intercepts are the simplest kind of *varying effects*. 

#+BEGIN_SRC R :results output 12.2
                                        # make the tank the cluster variable
d$tank <- 1:nrow(d)

                                        #fit
m12.1 <- map2stan(
    alist(
        surv ~ dbinom(density,p ),
        logit(p) <- a_tank[tank],
        a_tank[tank] ~ dnorm(0,5)
    ), data=d
)

precis(m12.1, depth=2)

#+END_SRC

#+RESULTS:
#+begin_example


SAMPLING FOR MODEL 'surv ~ dbinom(density, p)' NOW (CHAIN 1).
Chain 1: 
Chain 1: Gradient evaluation took 0.000257 seconds
Chain 1: 1000 transitions using 10 leapfrog steps per transition would take 2.57 seconds.
Chain 1: Adjust your expectations accordingly!
Chain 1: 
Chain 1: 
Chain 1: Iteration:    1 / 2000 [  0%]  (Warmup)
Chain 1: Iteration:  200 / 2000 [ 10%]  (Warmup)
Chain 1: Iteration:  400 / 2000 [ 20%]  (Warmup)
Chain 1: Iteration:  600 / 2000 [ 30%]  (Warmup)
Chain 1: Iteration:  800 / 2000 [ 40%]  (Warmup)
Chain 1: Iteration: 1000 / 2000 [ 50%]  (Warmup)
Chain 1: Iteration: 1001 / 2000 [ 50%]  (Sampling)
Chain 1: Iteration: 1200 / 2000 [ 60%]  (Sampling)
Chain 1: Iteration: 1400 / 2000 [ 70%]  (Sampling)
Chain 1: Iteration: 1600 / 2000 [ 80%]  (Sampling)
Chain 1: Iteration: 1800 / 2000 [ 90%]  (Sampling)
Chain 1: Iteration: 2000 / 2000 [100%]  (Sampling)
Chain 1: 
Chain 1:  Elapsed Time: 0.176343 seconds (Warm-up)
Chain 1:                0.156442 seconds (Sampling)
Chain 1:                0.332785 seconds (Total)
Chain 1: 

SAMPLING FOR MODEL 'surv ~ dbinom(density, p)' NOW (CHAIN 1).
Chain 1: 
Chain 1: Gradient evaluation took 1.1e-05 seconds
Chain 1: 1000 transitions using 10 leapfrog steps per transition would take 0.11 seconds.
Chain 1: Adjust your expectations accordingly!
Chain 1: 
Chain 1: 
Chain 1: WARNING: No variance estimation is
Chain 1:          performed for num_warmup < 20
Chain 1: 
Chain 1: Iteration: 1 / 1 [100%]  (Sampling)
Chain 1: 
Chain 1:  Elapsed Time: 1e-06 seconds (Warm-up)
Chain 1:                9.8e-05 seconds (Sampling)
Chain 1:                9.9e-05 seconds (Total)
Chain 1: 
Computing WAIC
Constructing posterior predictions
[ 100 / 1000 ][ 200 / 1000 ][ 300 / 1000 ][ 400 / 1000 ][ 500 / 1000 ][ 600 / 1000 ][ 700 / 1000 ][ 800 / 1000 ][ 900 / 1000 ][ 1000 / 1000 ]
Aggregated binomial counts detected. Splitting to 0/1 outcome for WAIC calculation.
Warning messages:
1: There were 1 divergent transitions after warmup. Increasing adapt_delta above 0.8 may help. See
http://mc-stan.org/misc/warnings.html#divergent-transitions-after-warmup 
2: Examine the pairs() plot to diagnose sampling problems

            Mean StdDev lower 0.89 upper 0.89 n_eff Rhat
a_tank[1]   2.50   1.16       0.70       4.09  1533 1.00
a_tank[2]   5.70   2.72       1.56       9.45   855 1.00
a_tank[3]   0.94   0.69      -0.11       2.13  1626 1.00
a_tank[4]   5.64   2.59       1.71       9.22   886 1.00
a_tank[5]   2.53   1.18       0.58       4.26  1108 1.00
a_tank[6]   2.47   1.09       0.81       4.18  1299 1.00
a_tank[7]   5.79   2.89       1.23       9.65   859 1.00
a_tank[8]   2.51   1.25       0.69       4.21   685 1.01
a_tank[9]  -0.44   0.71      -1.56       0.70  2383 1.00
a_tank[10]  2.57   1.21       0.72       4.35  1441 1.00
a_tank[11]  0.91   0.71      -0.10       2.23  2425 1.00
a_tank[12]  0.45   0.60      -0.44       1.39  2025 1.00
a_tank[13]  0.96   0.76      -0.30       2.12  1830 1.00
a_tank[14]  0.04   0.65      -0.96       1.06  2433 1.00
a_tank[15]  2.57   1.18       0.82       4.35  1264 1.00
a_tank[16]  2.49   1.16       0.59       4.03   892 1.00
a_tank[17]  3.48   1.11       1.80       5.26  1438 1.00
a_tank[18]  2.62   0.74       1.49       3.73  1429 1.00
a_tank[19]  2.12   0.64       1.13       3.14  1400 1.00
a_tank[20]  6.38   2.51       2.71      10.10   809 1.00
a_tank[21]  2.64   0.84       1.43       3.94  1408 1.00
a_tank[22]  2.62   0.83       1.35       3.94  1826 1.00
a_tank[23]  2.62   0.84       1.36       3.89  1343 1.00
a_tank[24]  1.72   0.57       0.67       2.46  1806 1.00
a_tank[25] -1.21   0.45      -1.90      -0.46  2188 1.00
a_tank[26]  0.09   0.43      -0.62       0.77  1742 1.00
a_tank[27] -1.75   0.55      -2.56      -0.89  2070 1.00
a_tank[28] -0.58   0.40      -1.24       0.03  1610 1.00
a_tank[29]  0.09   0.43      -0.63       0.75  3221 1.00
a_tank[30]  1.44   0.54       0.58       2.28  1732 1.00
a_tank[31] -0.77   0.44      -1.46      -0.07  1937 1.00
a_tank[32] -0.42   0.45      -1.18       0.24  2760 1.00
a_tank[33]  3.87   1.15       2.06       5.31  1007 1.00
a_tank[34]  3.00   0.84       1.62       4.18  1301 1.00
a_tank[35]  2.97   0.79       1.69       4.09  1287 1.00
a_tank[36]  2.12   0.53       1.29       2.88  1355 1.00
a_tank[37]  2.14   0.57       1.08       2.93  1598 1.00
a_tank[38]  6.72   2.60       3.02      10.58   792 1.00
a_tank[39]  2.96   0.77       1.77       4.07  1379 1.00
a_tank[40]  2.48   0.62       1.34       3.29  1891 1.00
a_tank[41] -2.12   0.55      -3.05      -1.33  1789 1.00
a_tank[42] -0.69   0.39      -1.35      -0.09  2081 1.00
a_tank[43] -0.53   0.35      -1.11      -0.03  2690 1.00
a_tank[44] -0.41   0.34      -0.94       0.10  1708 1.00
a_tank[45]  0.54   0.35       0.01       1.14  1988 1.00
a_tank[46] -0.67   0.37      -1.27      -0.11  2057 1.00
a_tank[47]  2.13   0.59       1.22       3.08  2063 1.00
a_tank[48] -0.06   0.35      -0.64       0.43  1917 1.00
#+end_example

*Hyperparameters* are parameters for parameters, their priors are called *hyperpriors*.

#+BEGIN_SRC R :results output
m12.2 <- map2stan(
    alist(
        surv ~ dbinom(density, p),
        logit(p) <- a_tank[tank],
        a_tank[tank] ~ dnorm(a, sigma),
        a ~ dnorm(0,1),
        sigma ~ dcauchy(0,1)
    ), data=d, iter=4000, chains=4)

compare(m12.1, m12.2)

#+END_SRC

#+RESULTS:
#+begin_example


SAMPLING FOR MODEL 'surv ~ dbinom(density, p)' NOW (CHAIN 1).
Chain 1: 
Chain 1: Gradient evaluation took 3.6e-05 seconds
Chain 1: 1000 transitions using 10 leapfrog steps per transition would take 0.36 seconds.
Chain 1: Adjust your expectations accordingly!
Chain 1: 
Chain 1: 
Chain 1: Iteration:    1 / 4000 [  0%]  (Warmup)
Chain 1: Iteration:  400 / 4000 [ 10%]  (Warmup)
Chain 1: Iteration:  800 / 4000 [ 20%]  (Warmup)
Chain 1: Iteration: 1200 / 4000 [ 30%]  (Warmup)
Chain 1: Iteration: 1600 / 4000 [ 40%]  (Warmup)
Chain 1: Iteration: 2000 / 4000 [ 50%]  (Warmup)
Chain 1: Iteration: 2001 / 4000 [ 50%]  (Sampling)
Chain 1: Iteration: 2400 / 4000 [ 60%]  (Sampling)
Chain 1: Iteration: 2800 / 4000 [ 70%]  (Sampling)
Chain 1: Iteration: 3200 / 4000 [ 80%]  (Sampling)
Chain 1: Iteration: 3600 / 4000 [ 90%]  (Sampling)
Chain 1: Iteration: 4000 / 4000 [100%]  (Sampling)
Chain 1: 
Chain 1:  Elapsed Time: 0.317911 seconds (Warm-up)
Chain 1:                0.26887 seconds (Sampling)
Chain 1:                0.586781 seconds (Total)
Chain 1: 

SAMPLING FOR MODEL 'surv ~ dbinom(density, p)' NOW (CHAIN 2).
Chain 2: 
Chain 2: Gradient evaluation took 1e-05 seconds
Chain 2: 1000 transitions using 10 leapfrog steps per transition would take 0.1 seconds.
Chain 2: Adjust your expectations accordingly!
Chain 2: 
Chain 2: 
Chain 2: Iteration:    1 / 4000 [  0%]  (Warmup)
Chain 2: Iteration:  400 / 4000 [ 10%]  (Warmup)
Chain 2: Iteration:  800 / 4000 [ 20%]  (Warmup)
Chain 2: Iteration: 1200 / 4000 [ 30%]  (Warmup)
Chain 2: Iteration: 1600 / 4000 [ 40%]  (Warmup)
Chain 2: Iteration: 2000 / 4000 [ 50%]  (Warmup)
Chain 2: Iteration: 2001 / 4000 [ 50%]  (Sampling)
Chain 2: Iteration: 2400 / 4000 [ 60%]  (Sampling)
Chain 2: Iteration: 2800 / 4000 [ 70%]  (Sampling)
Chain 2: Iteration: 3200 / 4000 [ 80%]  (Sampling)
Chain 2: Iteration: 3600 / 4000 [ 90%]  (Sampling)
Chain 2: Iteration: 4000 / 4000 [100%]  (Sampling)
Chain 2: 
Chain 2:  Elapsed Time: 0.297148 seconds (Warm-up)
Chain 2:                0.200546 seconds (Sampling)
Chain 2:                0.497694 seconds (Total)
Chain 2: 

SAMPLING FOR MODEL 'surv ~ dbinom(density, p)' NOW (CHAIN 3).
Chain 3: 
Chain 3: Gradient evaluation took 1.1e-05 seconds
Chain 3: 1000 transitions using 10 leapfrog steps per transition would take 0.11 seconds.
Chain 3: Adjust your expectations accordingly!
Chain 3: 
Chain 3: 
Chain 3: Iteration:    1 / 4000 [  0%]  (Warmup)
Chain 3: Iteration:  400 / 4000 [ 10%]  (Warmup)
Chain 3: Iteration:  800 / 4000 [ 20%]  (Warmup)
Chain 3: Iteration: 1200 / 4000 [ 30%]  (Warmup)
Chain 3: Iteration: 1600 / 4000 [ 40%]  (Warmup)
Chain 3: Iteration: 2000 / 4000 [ 50%]  (Warmup)
Chain 3: Iteration: 2001 / 4000 [ 50%]  (Sampling)
Chain 3: Iteration: 2400 / 4000 [ 60%]  (Sampling)
Chain 3: Iteration: 2800 / 4000 [ 70%]  (Sampling)
Chain 3: Iteration: 3200 / 4000 [ 80%]  (Sampling)
Chain 3: Iteration: 3600 / 4000 [ 90%]  (Sampling)
Chain 3: Iteration: 4000 / 4000 [100%]  (Sampling)
Chain 3: 
Chain 3:  Elapsed Time: 0.303589 seconds (Warm-up)
Chain 3:                0.244817 seconds (Sampling)
Chain 3:                0.548406 seconds (Total)
Chain 3: 

SAMPLING FOR MODEL 'surv ~ dbinom(density, p)' NOW (CHAIN 4).
Chain 4: 
Chain 4: Gradient evaluation took 1.2e-05 seconds
Chain 4: 1000 transitions using 10 leapfrog steps per transition would take 0.12 seconds.
Chain 4: Adjust your expectations accordingly!
Chain 4: 
Chain 4: 
Chain 4: Iteration:    1 / 4000 [  0%]  (Warmup)
Chain 4: Iteration:  400 / 4000 [ 10%]  (Warmup)
Chain 4: Iteration:  800 / 4000 [ 20%]  (Warmup)
Chain 4: Iteration: 1200 / 4000 [ 30%]  (Warmup)
Chain 4: Iteration: 1600 / 4000 [ 40%]  (Warmup)
Chain 4: Iteration: 2000 / 4000 [ 50%]  (Warmup)
Chain 4: Iteration: 2001 / 4000 [ 50%]  (Sampling)
Chain 4: Iteration: 2400 / 4000 [ 60%]  (Sampling)
Chain 4: Iteration: 2800 / 4000 [ 70%]  (Sampling)
Chain 4: Iteration: 3200 / 4000 [ 80%]  (Sampling)
Chain 4: Iteration: 3600 / 4000 [ 90%]  (Sampling)
Chain 4: Iteration: 4000 / 4000 [100%]  (Sampling)
Chain 4: 
Chain 4:  Elapsed Time: 0.306997 seconds (Warm-up)
Chain 4:                0.214722 seconds (Sampling)
Chain 4:                0.521719 seconds (Total)
Chain 4: 

SAMPLING FOR MODEL 'surv ~ dbinom(density, p)' NOW (CHAIN 1).
Chain 1: 
Chain 1: Gradient evaluation took 1.5e-05 seconds
Chain 1: 1000 transitions using 10 leapfrog steps per transition would take 0.15 seconds.
Chain 1: Adjust your expectations accordingly!
Chain 1: 
Chain 1: 
Chain 1: WARNING: No variance estimation is
Chain 1:          performed for num_warmup < 20
Chain 1: 
Chain 1: Iteration: 1 / 1 [100%]  (Sampling)
Chain 1: 
Chain 1:  Elapsed Time: 2e-06 seconds (Warm-up)
Chain 1:                8.3e-05 seconds (Sampling)
Chain 1:                8.5e-05 seconds (Total)
Chain 1: 
Computing WAIC
Constructing posterior predictions
[ 800 / 8000 ][ 1600 / 8000 ][ 2400 / 8000 ][ 3200 / 8000 ][ 4000 / 8000 ][ 4800 / 8000 ][ 5600 / 8000 ][ 6400 / 8000 ][ 7200 / 8000 ][ 8000 / 8000 ]
Aggregated binomial counts detected. Splitting to 0/1 outcome for WAIC calculation.
Warning messages:
1: There were 1 divergent transitions after warmup. Increasing adapt_delta above 0.8 may help. See
http://mc-stan.org/misc/warnings.html#divergent-transitions-after-warmup 
2: Examine the pairs() plot to diagnose sampling problems

        WAIC pWAIC dWAIC weight    SE  dSE
m12.2 1009.8  37.8   0.0      1 37.96   NA
m12.1 1024.2  49.9  14.4      0 42.99 6.61
#+end_example

#+BEGIN_SRC R :results graphics :file 12.5.png
#extract stan samples
post <- extract.samples(m12.2)

                                        #compute median intercept for each tank
                                        # also transform to probability with logistic
d$propsurv.est <- logistic(apply(post$a_tank, 2, median))

                                        # display raw proportions surviving in each tank
plot(d$propsurv, ylim=c(0,1), pch=16, xaxt='n',
     xlab="tank", ylab="proportion survival", col=rangi2)
axis(1, at=c(1,16,32,48), labels=c(1,16,32,48))


                                        #overlay posterior means
points(d$propsurv.est)

                                        #mark posterior median probability across tanks
abline(h=logistic(median(post$a)), lty=2)

                                        # draw vertical dividers between tanks
abline(v=16.5, lwd=0.5)
abline(v=32.5, lwd=0.5)
text(8, 0, "small tanks")
text(16+8, 0, "medium tanks")
text(32+8, 0, "large tanks")
#+END_SRC

#+RESULTS:
[[file:12.5.png]]

*Shrinkage* results from regularizatin. Moving towards multilevel estimate-estimated
 median survival proportion.

*Pooling* each tank provides information that can be used to improve the estimates for all
the other tanks. 

'Sampling' from a posterior distribution is not a simulation of empirical sampling. It's
just a convenient way to characterize and work with the uncertainty in the distribution. 

#+BEGIN_SRC R :results graphics :file 12.6.png :width 600
# show first 100 populations in the posterior

par(mfrow=c(1,2))

plot(NULL, xlim=c(-3,4), ylim=c(0,0.35),
     xlab="log-odds survive", ylab="Density")
for (i in 1:100)
    curve(dnorm(x, post$a[i], post$sigma[i]), add=TRUE,
          col=col.alpha("black", 0.2))

                                        # sample 8000 imaginary tanks from the posterior distribution
sim_tanks <- rnorm(8000, post$a, post$sigma)

                                        # transform to probability and visualize
dens(logistic(sim_tanks), xlab="probability survive")

#+END_SRC

#+RESULTS:
[[file:12.6.png]]

* 12.2. Varying effects and the underfitting/overfitting trade-off

Varying intercepts are just regularized estimates, but adaptively regularized by
estimating how diverse the clusters are while estimates the features of each cluster. The
reason that the varying intercepts provide better estimates is that they do a better job
of trading off underfitting and overfitting. 

1. Suppose you use overall mean \sigma, to make your predictions. Quite precise because of
   lot of data, however, unlikely to fit the mean of a particular cluster. The total
   sample mean underfits the data. *Complete pooling* and assumes that variation among
   ponds is zero. 
2. Make separate intercepts for each cluster. Little data contributes to estimate > thus
   imprecise, especially for smaller clusters. Error of the estimates is high and they are
   overfit to the data. *No pooling* estimates. 
3. When you estimate varying intercepts, you use *partial pooling* of information to
   produce estimates for each cluster that are less underfit than the grand mean and less
   overfit than the no-pooling estimates. For large cluster difference will be less than
   for smaller clusters. 

Learning to simulate and validate models and model fitting is extremely valuable. 

** 12.2.1. The model
To simulate data, we need to assign values to:
- \alpha, the average log-odds of survival in the entire popularion of ponds
- \sigma, the standard deviation of the distribution of log-odds of survival among ponds
- \alpha_{pond}, a vector of individual pond intercepts, one for each pond

Assign sample sizes to each cluster. 

** 12.2.2. Assign values to the parameters
#+BEGIN_SRC R
a <- 1.4
sigma <- 1.5
nponds <- 60
ni <- as.integer(rep(c(5,10,25,35), each=15))

a_pond <- rnorm(nponds, mean=a, sd=sigma)

dsim <- data.frame(pond=1:nponds, ni=ni, true_a=a_pond)

#+END_SRC

#+RESULTS:
|  1 |  5 |   0.225794433177051 |
|  2 |  5 |   0.605146469207773 |
|  3 |  5 |    1.33621060303039 |
|  4 |  5 | -0.0561684666004982 |
|  5 |  5 |   0.369687085908959 |
|  6 |  5 |    -1.1266091839586 |
|  7 |  5 |    3.99696680752727 |
|  8 |  5 |   0.983937357720886 |
|  9 |  5 |    1.60806852829007 |
| 10 |  5 |    2.17145170762797 |
| 11 |  5 |   -1.21747948200918 |
| 12 |  5 |    2.57348536314443 |
| 13 |  5 |  -0.208218696362222 |
| 14 |  5 |  0.0481138396602949 |
| 15 |  5 |    3.35343475927604 |
| 16 | 10 |    1.94008322936487 |
| 17 | 10 |    1.23097062212745 |
| 18 | 10 |    2.04477053417306 |
| 19 | 10 |   0.303734415652394 |
| 20 | 10 |    3.41588060640608 |
| 21 | 10 | -0.0430782723994028 |
| 22 | 10 |    3.62714328063718 |
| 23 | 10 |     2.6191616948965 |
| 24 | 10 |   0.010152098622684 |
| 25 | 10 |    2.17879575505265 |
| 26 | 10 |    1.10115431009209 |
| 27 | 10 |    4.18379626337166 |
| 28 | 10 |    1.84623749436884 |
| 29 | 10 |    6.13071400800151 |
| 30 | 10 |    2.00574087758308 |
| 31 | 25 |    1.01674823433589 |
| 32 | 25 |   -2.11388730108453 |
| 33 | 25 |     4.9285760920417 |
| 34 | 25 |  -0.947170464043352 |
| 35 | 25 |    2.97065311627129 |
| 36 | 25 |    2.11400651763373 |
| 37 | 25 |   0.392738901177263 |
| 38 | 25 |    4.08893499111627 |
| 39 | 25 |     2.3431353314882 |
| 40 | 25 |    2.51967308427494 |
| 41 | 25 |    2.35442228093249 |
| 42 | 25 |    3.68005177826286 |
| 43 | 25 |  -0.847585738535799 |
| 44 | 25 |   0.911530281092989 |
| 45 | 25 |    2.58165285910591 |
| 46 | 35 |  -0.653990881270582 |
| 47 | 35 |   0.717436080911701 |
| 48 | 35 |      1.380005354761 |
| 49 | 35 |    3.18724834475689 |
| 50 | 35 |  -0.519240424236769 |
| 51 | 35 |    2.68468005381931 |
| 52 | 35 |   -1.76163527366527 |
| 53 | 35 |   -1.09118120595644 |
| 54 | 35 |    2.76279541240414 |
| 55 | 35 |  -0.643668252051202 |
| 56 | 35 |    2.30676717553626 |
| 57 | 35 |    3.61812587808525 |
| 58 | 35 |    1.73580701224462 |
| 59 | 35 |   -1.70519283645617 |
| 60 | 35 |    1.54650119012378 |

** 12.2.3. Simulate Survivors
Each pond $i$ has $n_{i}$ potential survivors and nature flips each tadpole's coin with
probability of survival $p_{i}$. this probability $p_{i}$ is implied by the model definition

$$p_{i} = \dfrac{exp(\alpha_{i})}{1 + exp(\alpha_{i})}$$


#+BEGIN_SRC R
dsim$si <- rbinom(nponds, prob=logistic(dsim$true_a), size=dsim$ni)
#+END_SRC

#+RESULTS:
|  4 |
|  2 |
|  5 |
|  3 |
|  5 |
|  0 |
|  5 |
|  2 |
|  5 |
|  5 |
|  1 |
|  4 |
|  3 |
|  3 |
|  5 |
|  8 |
|  8 |
|  8 |
|  5 |
| 10 |
|  5 |
| 10 |
|  9 |
|  4 |
|  8 |
|  8 |
| 10 |
| 10 |
| 10 |
|  8 |
| 20 |
|  0 |
| 25 |
|  8 |
| 23 |
| 23 |
| 11 |
| 24 |
| 24 |
| 23 |
| 25 |
| 25 |
|  8 |
| 21 |
| 21 |
| 11 |
| 22 |
| 31 |
| 35 |
| 13 |
| 34 |
|  2 |
| 11 |
| 32 |
| 12 |
| 30 |
| 34 |
| 30 |
|  4 |
| 28 |

** 12.2.4. Compute the no-pooling estimates 

#+BEGIN_SRC R
dsim$p_nopool <- dsim$si /dsim$ni

#+END_SRC

#+RESULTS:
|                0.8 |
|                0.4 |
|                  1 |
|                0.6 |
|                  1 |
|                  0 |
|                  1 |
|                0.4 |
|                  1 |
|                  1 |
|                0.2 |
|                0.8 |
|                0.6 |
|                0.6 |
|                  1 |
|                0.8 |
|                0.8 |
|                0.8 |
|                0.5 |
|                  1 |
|                0.5 |
|                  1 |
|                0.9 |
|                0.4 |
|                0.8 |
|                0.8 |
|                  1 |
|                  1 |
|                  1 |
|                0.8 |
|                0.8 |
|                  0 |
|                  1 |
|               0.32 |
|               0.92 |
|               0.92 |
|               0.44 |
|               0.96 |
|               0.96 |
|               0.92 |
|                  1 |
|                  1 |
|               0.32 |
|               0.84 |
|               0.84 |
|  0.314285714285714 |
|  0.628571428571429 |
|  0.885714285714286 |
|                  1 |
|  0.371428571428571 |
|  0.971428571428571 |
| 0.0571428571428571 |
|  0.314285714285714 |
|  0.914285714285714 |
|  0.342857142857143 |
|  0.857142857142857 |
|  0.971428571428571 |
|  0.857142857142857 |
|  0.114285714285714 |
|                0.8 |

This column contains the empirical proportions of survivors in each pond. These are the
same no-pooling estimates you'd get by fitting a model with a dummy variable for each pond
and flat priors tht induce no regularization. 

** 12.2.5. Compute the partial-pooling estimates
#+BEGIN_SRC R
m12.3 <- map2stan(
    alist(
        si ~ dbinom(ni, p),
        logit(p) <- a_pond[pond],
        a_pond[pond] ~ dnorm(a, sigma),
        a ~ dnorm(0, 1),
        sigma ~ dcauchy(0, 1)
    ), data=dsim, iter=1e4, warmup=1000)

precis(m12.3, depth=2)

#+END_SRC

#+RESULTS:

#+BEGIN_SRC R :results graphics :file 12.18.png
estimated.a_pond <- as.numeric(coef(m12.3)[1:60])
dsim$p_partpool <- logistic(estimated.a_pond)

#true per-pond survival probabilities
dsim$p_true <- logistic(dsim$true_a)

#compute absolute error between the estimates and the true varying effects
nopool_error <- abs(dsim$p_nopool - dsim$p_true)
partpool_error <- abs(dsim$p_partpool - dsim$p_true)

plot(1:60, nopool_error, xlab="pond", ylab="absolute error",
     col=rangi2, pch=16)
points(1:60, partpool_error)


#+END_SRC

#+RESULTS:
[[file:12.18.png]]

* 12.3 More than one type of cluster

** 12.3.1. Multilevel chimpanzees
#+BEGIN_SRC R
library(rethinking)
data(chimpanzees)
d <- chimpanzees
d$recipient <- NULL

m12.4 <- map2stan(
    alist(
        pulled_left ~ dbinom(1,p),
        logit(p) <- a + a_actor[actor] + (bp + bpC*condition)*prosoc_left,
        a_actor[actor] ~ dnorm(0, sigma_actor),
        a ~ dnorm(0,10),
        bp~ dnorm(0,10),
        bpC ~ dnorm(0,10),
        sigma_actor ~ dcauchy(0,1)
    ), data=d, warmup=1000, iter=5000, chains=4, cores=4)

post <- extract.samples(m12.4)
total_a_actor <- sapply(1:7, function(actor) post$a + post$a_actor[,actor])
round(apply(total_a_actor, 2, mean), 2)

#+END_SRC

#+RESULTS:
| -0.71 |
|  4.61 |
| -1.02 |
| -1.02 |
| -0.72 |
|  0.23 |
|  1.76 |

#+BEGIN_SRC R :results graphics :file m12.4.png
plot(m12.4)

#+END_SRC

#+RESULTS:
[[file:m12.4.png]]

** 12.3.2. Two types of cluster
#+BEGIN_SRC R :results graphics :file m12.5.png
d$block_id <- d$block #block name is reserved by stan

m12.5 <- map2stan(
    alist(
        pulled_left ~ dbinom(1,p),
        logit(p) <- a + a_actor[actor] + a_block[block_id] +
            (bp + bpc*condition) * prosoc_left,
        a_actor[actor] ~ dnorm(0, sigma_actor),
        a_block[block_id] ~ dnorm(0, sigma_block),
        c(a, bp, bpc) ~ dnorm(0, 10),
        sigma_actor ~ dcauchy(0,1),
        sigma_block ~ dcauchy(0,1)
    ), data=d, warmup=1000, iter=6000, chains=4, cores=4)

precis(m12.5, depth=2)
plot(precis(m12.5, depth=2))
#+END_SRC

#+BEGIN_SRC R :results graphics :file 12-25.png
post <- extract.samples(m12.5)
dens(post$sigma_block, xlab="sigma", xlim=c(0,4))
dens(post$sigma_actor, col=rangi2, lwd=2, add=TRUE)
text(2, 0.85, "actor", col=rangi2)
text(0.75, 2, "block")

#+END_SRC

#+RESULTS:
[[file:12-25.png]]

* 12.4 Multilevel posterior predictions

** 12.4.1. Posterior predictions for same clusters
#+BEGIN_SRC R :results output
chimp <- 2
d.pred <- list(
    prosoc_left = c(0,1,0,1), #right/left/right/left
    condition = c(0,0,1,1),
    actor = rep(chimp,4)
)

link.m12.4 <- link(m12.4, data=d.pred)
pred.p <- apply(link.m12.4, 2, mean)
pred.p.PI <- apply(link.m12.4, 2, PI)
#+END_SRC

#+RESULTS:
: 
: [ 100 / 1000 ][ 200 / 1000 ][ 300 / 1000 ][ 400 / 1000 ][ 500 / 1000 ][ 600 / 1000 ][ 700 / 1000 ][ 800 / 1000 ][ 900 / 1000 ][ 1000 / 1000 ]

#+BEGIN_SRC R
p.link <- function(prosoc_left, condition, actor){
    logodds <- with(post, a + a_actor[,actor] + (bp + bpc * condition)
                    ,* prosoc_left)
    return(logistic(logodds))
}

prosoc_left <- c(0,1,0,1)
condition <- c(0,0,1,1)
pred.raw <- sapply(1:4, function(i) p.link(prosoc_left[i], condition[i],2))
pred.p <- apply(pred.raw, 2, mean)
pred.p.PI <- apply(pred.raw, 2, PI)

#+END_SRC

#+RESULTS:
| 0.943846615558391 | 0.973678740559372 | 0.943846615558391 |  0.97024557335579 |
| 0.999378919404614 | 0.999735353186377 | 0.999378919404614 | 0.999698755794183 |

** 12.4.2. Posterior prediction for new clusters
#+BEGIN_SRC R :results graphics :file 12-34.png
d.pred <- list(
    prosoc_left = c(0,1,0,1),
    condition = c(0,0,1,1),
    actor = rep(2,4))

                                        # replace varying intercept samples with zeros
                                        # 1000 samples by 7 actors
a_actor_zeros <- matrix(0,1000,7)

                                        #fire up link
                                        # note use of replace list
link.m12.4 <- link(m12.4, n=1000, data=d.pred,
                   replace=list(a_actor=a_actor_zeros))

                                        #summarize and plot

pred.p.mean <- apply(link.m12.4, 2, mean)
pred.p.PI <- apply(link.m12.4, 2, PI, prob=0.8)
plot(0, 0, type="n", xlab="prosoc_left/condition",
     ylab="proportion pulled left", ylim=c(0,1), xaxt="n",
     xlim=c(1,4))
axis(1, at=1:4, labels=c("0/0","1/0","0/1","1/1"))
lines(1:4, pred.p.mean)
shade(pred.p.PI, 1:4)


#+END_SRC

#+RESULTS:
[[file:12-34.png]]

#+BEGIN_SRC R :results graphics :file 12-35.png
#replace varying intercept samples with simulations
post <- extract.samples(m12.4)
a_actor_sims <- rnorm(7000,0,post$sigma_actor)
a_actor_sims <- matrix(a_actor_sims, 1000, 7)

link.m12.4 <- link(m12.4, n=1000, data=d.pred,
                   replace=list(a_actor=a_actor_sims))


pred.p.mean <- apply(link.m12.4, 2, mean)
pred.p.PI <- apply(link.m12.4, 2, PI, prob=0.8)
plot(0, 0, type="n", xlab="prosoc_left/condition",
     ylab="proportion pulled left", ylim=c(0,1), xaxt="n",
     xlim=c(1,4))
axis(1, at=1:4, labels=c("0/0","1/0","0/1","1/1"))
lines(1:4, pred.p.mean)
shade(pred.p.PI, 1:4)


#+END_SRC

#+RESULTS:
[[file:12-35.png]]

The predictions for an average actor help to visualize the impact of treatment
The predictions that are marginal of actor illustrate how vaeriable different actors are,
according to the model. 

#+BEGIN_SRC R :results graphics :file 12-38.png
post <- extract.samples(m12.4)
sim.actor <- function(i) {
    sim_a_actor <- rnorm(1, 0, post$sigma_actor[i])
    P <- c(0,1,0,1)
    C <- c(0,0,1,1)
    p <- logistic(post$a[i] +
                  sim_a_actor +
                  (post$bp[i] + post$bpC[i] * C)*P)
    return(p)
}

                                        #empty plot
plot(0, 0, type="n", xlab="prosoc_left/condition",
     ylab="proportion pulled left", ylim=c(0,1), xaxt="n", xlim=c(1,4))
axis(1, at=1:4, labels=c("0/0", "1/0", "0/1", "1/1"))

                                        #plot 50 simulated actors
for (i in 1:100) lines(1:4, sim.actor(i), col=col.alpha("black", 0.5))

#+END_SRC

#+RESULTS:
[[file:12-38.png]]

Multilevel models contain parameters with different *focus*. Focus here means which level
of the model the parameter makes direct predictions for. 

1. When retrodicting the sample, the parameters that decribe the population of clusters do
   not influence prediction directly. *Hyperparameter* had their effect during estimation,
   by shrinking the varying effect parameters towards a common mean.
2. The same is true when forecasting a new observation for a cluster that was present in
   the sample. 
3. When instead we wish to forecast for some new cluster that wasn ot present in the
   sample, such as a new individual or school or year or location, then we need the
   hyper-parameters. The hyper-parameters tell us how to forecast a new cluster, by
   generating a distribution of new per-cluster intercepts. 

In the case of *over-dispersion*, we need to simulate intercepts to account for the
over-dispersion. 

By estimating the distribution of residuals, we get an estimate of the excess variation,
relative to the Poisson expectation. 

#+BEGIN_SRC R :results graphics :file m12-41.png
library(rethinking)
data(Kline)
d <- Kline
d$logpop <- log(d$population)
d$society <- 1:10

                                        # fit models
m12.6 <- map2stan(
    alist(
        total_tools ~ dpois(mu),
        log(mu) <- a + a_society[society] + bp*logpop,
        a ~ dnorm(0,10),
        bp ~ dnorm(0,1),
        a_society[society] ~ dnorm(0, sigma_society),
        sigma_society ~ dcauchy(0,1)
    ), data=d, iter=4000, chains=3)

                                        # you can use postcheck but those predictions use the varying intercepts directly. they do not use the hyper-parameters

                                        # we need to simulate counterfactual societies, using the hyper-parameters.

post <- extract.samples(m12.6)
d.pred <- list(
    logpop = seq(from=6, to=14, length.out=30),
    society=rep(1,30))

a_society_sims <- rnorm(20000, 0, post$sigma_society)
a_society_sims <- matrix(a_society_sims, 2000, 10)
link.m12.6 <- link(m12.6, n=2000, data=d.pred,
                   replace=list(a_society=a_society_sims))

                                        #plot raw data
plot(d$logpop, d$total_tools, col=rangi2, pch=16,
     xlab="log population", ylab="total tools")

                                        #plot posterior median
mu.median <- apply(link.m12.6, 2, median)
lines(d.pred$logpop, mu.median)


mu.PI <- apply(link.m12.6, 2, PI, prob=0.97)
shade(mu.PI, d.pred$logpop)

mu.PI <- apply(link.m12.6, 2, PI, prob=0.89)
shade(mu.PI, d.pred$logpop)

mu.PI <- apply(link.m12.6, 2, PI, prob=0.67)
shade(mu.PI, d.pred$logpop)


#+END_SRC

#+RESULTS:
[[file:m12-41.png]]
* 12.5. Summary
This chapter has been an introduction to the motivation, implementation, and inter-
pretation of basic multilevel models. It focused on varying intercepts, which achieve
better estimates of baseline differences among clusters in the data. They achieve better
estimates, because they simultaneously model the population of clusters and use inferences
about the population to pool information among parameters. From another perspective,
varying intercepts are adaptively regularized parameters, relying upon a prior that is
itself learned from the data. All of this is a foundation for the next chapter, which
extends these concepts to additional types of parameters and models.

* 12.6 Practice

** 12E1
a. This prior is narrower and thus more regularizing, leading to more /shrinkage/

** 12E2
#+BEGIN_SRC R
m12E2 <- map2stan(
    alist(
        y ~ dbinom(1, p ),
        logit(p) <- a_group[i] + b*x_{i},
        a_group[i] ~ dnorm(a_2, sigma),
        b ~ dnorm(0,1),
        a_2 ~ dnorm(0,1)
        sigma ~ dcauchy(0,1)
    )

#+END_SRC

** 12E3
The same as 12E2

** 12E4
#+BEGIN_SRC R
m12e4 <- map2stan(
    alist(
        y ~ dpois(lambda),
        log(lambda) <- a_group[i] + b*x_{i},
        a_group[i] ~ dnorm(a_2, sigma),
        b ~ dnorm(0,1),
        a_2 ~ dnorm(0,1),
        sigma ~ dcauchy(0,1)
    ), data)

#+END_SRC

** 12E5
#+BEGIN_SRC R
m12E5 <- map2stan(
    alist(
        y ~ dpois(lambda),
        log(lambda) <- a_group[i] + a_year[y] + b_1*x + b_2*x,
        a_group[i] ~ dnorm(a_2, sigma),
        a_year[y] ~ dorm(a_1, sigma_2)
        a_2 ~ dnorm(0,1),
        a_1 ~ dnorm(0,1),
        b_1 ~ dnorm(0,1),
        b_2 ~ dnorm(0,1),
        sigma ~ dcauch(0,1),
        sigma_2 ~ dcauchy(0,1)
    ))

#+END_SRC

** 12M1
#+BEGIN_SRC R
library(rethinking)
data(reedfrogs)
d <- reedfrogs

d$tank <- 1:nrow(d)
d$predation <- ifelse(d$pred == 'pred', 1, 0)
d$size_dummy <- ifelse(d$size =='big', 1, 0)


m12m1.predation <- map2stan(
    alist(
        surv ~ dbinom(density, p),
        logit(p) <- a_tank[tank] + b_p * predation,
        a_tank[tank] ~ dnorm(a, sigma),
        a ~ dnorm(0, 1),
        b_p ~ dnorm(0, 1),
        sigma ~ dcauchy(0, 1)
    ), data=d, iter=4000, chains=4)


m12m1.size <- map2stan(
    alist(
        surv ~ dbinom(density, p),
        logit(p) <- a_tank[tank] + b_s * size_dummy,
        a_tank[tank] ~ dnorm(a, sigma),
        a ~ dnorm(0, 1),
        b_s ~ dnorm(0,1),
        sigma ~ dcauchy(0, 1)
    ), data=d, iter=4000, chains=4)


m12m1.predation.size <- map2stan(
    alist(
        surv ~ dbinom(density, p),
        logit(p) <- a_tank[tank] + b_s * size_dummy + b_p * predation,
        a_tank[tank] ~ dnorm(a, sigma),
        a ~ dnorm(0, 1),
        b_s ~ dnorm(0, 1),
        b_p ~ dnorm(0, 1),
        sigma ~ dcauchy(0, 1)
    ), data=d, iter=4000, chains=4)


m12m1.predation.size.int <- map2stan(
    alist(
        surv ~ dbinom(density, p),
        logit(p) <- a_tank[tank] + b_s * size_dummy + b_p * predation + b_p_s * predation * size_dummy,
        a_tank[tank] ~ dnorm(a, sigma),
        a ~ dnorm(0, 1),
        b_s ~ dnorm(0, 1),
        b_p ~ dnorm(0, 1),
        b_p_s ~ dnorm(0, 1),
        sigma ~ dcauchy(0, 1)
    ), data=d, iter=4000, chains=4)

#coeftab(m12M1.predation, m12M1.size, m12M1.both, m12M1.interaction)


#+END_SRC

#+RESULTS:
[[file:12m1.png]]

#+BEGIN_SRC R :results graphics :file 12m1.png

# posterior predictive check
plot_posterior_medians <- function(model, data) {
  post <- extract.samples(model)

  # compute median intercept for each tank
  # also transform to probability with logistic

  data$propsurv.est <- logistic( apply(post$a_tank, 2, median))

  # display raw proportions surviving in each tank
  plot( data$propsurv , ylim=c(0,1) , pch=16 , xaxt="n" ,
        xlab="tank" , ylab="proportion survival" , col=rangi2 )
  axis( 1 , at=c(1,16,32,48) , labels=c(1,16,32,48) )

  # overlay posterior medians
  points( data$propsurv.est )

  # mark posterior median probability across tanks
  abline( h=logistic(median(post$a)) , lty=2 )

  # draw vertical dividers between tank densities
  abline( v=16.5 , lwd=0.5 )
  abline( v=32.5 , lwd=0.5 )
  text( 8 , 0 , "small tanks" )
  text( 16+8 , 0 , "medium tanks" )
  text( 32+8 , 0 , "large tanks" )
}

par(mfrow=c(2,2))


plot_posterior_medians(model = m12m1.predation, data = d)
plot_posterior_medians(model = m12m1.size, data = d)
plot_posterior_medians(model = m12m1.predation.size, data = d)
plot_posterior_medians(model = m12m1.predation.size.int, data = d)


#+END_SRC

#+RESULTS:
[[file:12m1.png]]

The more predictors we add the closer the predictions move towards median. Thus less
variance between tanks. Variance is less because of the overfitting of the model. The
self-learning regulariation is less impactful. 

** 12M2 
#+BEGIN_SRC R :results output
compare(m12m1.predation, m12m1.size, m12m1.predation.size, m12m1.predation.size.int)
coeftab(m12m1.predation, m12m1.size, m12m1.prediation.size, m12m1.predation.size.int)

#+END_SRC

#+RESULTS:
:                            WAIC pWAIC dWAIC weight    SE  dSE
: m12m1.predation.size.int 1000.7  27.3   0.0   0.43 37.01   NA
: m12m1.predation          1001.2  28.6   0.5   0.34 36.70 2.83
: m12m1.predation.size     1001.9  28.5   1.2   0.24 36.82 2.63
: m12m1.size               1010.4  38.1   9.7   0.00 38.04 7.11

** 12M3
#+BEGIN_SRC R :results graphics :file 12m3.png

m12m3.cauchy <- map2stan(
    alist(
        surv ~ dbinom(density, p),
        logit(p) <- a_tank[tank],
        a_tank[tank] ~ dcauchy(a, sigma),
        a ~ dnorm(0,1),
        sigma ~ dcauchy(0,1)
        ), data=d, iter=4000, chains=4)

m12m3.gaussian <- map2stan(
  alist(
    surv ~ dbinom(density, p) ,
    logit(p) <- a_tank[tank],
    a_tank[tank] ~ dnorm(a, sigma),
    a ~ dnorm(0, 10),
    sigma ~ dcauchy(0, 1)
  ), data=d, iter=4000, chains=4 )

#+END_SRC

#+RESULTS:
[[file:12m3.png]]

#+BEGIN_SRC R :results graphics :file 12m3.png

coeftab(m12m3.cauchy, m12m3.gaussian)

post_gaussian <- extract.samples(m12m3.gaussian)
alpha_gaussian <- apply(post_gaussian$a_tank, 2, mean)

post_cauchy <- extract.samples(m12m3.cauchy)
alpha_cauchy <- apply(post_cauchy$a_tank,2,mean)
plot( alpha_gaussian, alpha_cauchy , pch=16 , col=rangi2 ,
      xlab="Gaussian prior" , ylab="Cauchy prior" )
abline(a=0, b=1, lty=2)


#+END_SRC

#+RESULTS:
[[file:12m3.png]]

The Cauchy model has a long tail, this explains why for extreme values there are moments
when shrinkage is less present. 

** 12M4
#+BEGIN_SRC R
library(rethinking)
data(chimpanzees)
d <- chimpanzees
d$recipient <- NULL
d$block_id <- d$block


m12.4.chapter <- map2stan(
    alist(
        pulled_left ~ dbinom(1, p),
        logit(p) <- a + a_actor[actor] + a_block[block_id] + (bp + bpc*condition) * prosoc_left,
        a_actor[actor] ~ dnorm(0, sigma_actor),
        a_block[block_id] ~ dnorm(0, sigma_block),
        c(a, bp, bpc) ~ dnorm(0, 10),
        c(sigma_actor, sigma_block) ~ dcauchy(0,1)
    ), data=d, warmup=1000, iter=6000, chains=4, cores=4)

precis(m12.4.chapter, depth=2)


m12.4 <- map2stan(
    alist(
        pulled_left ~ dbinom(1, p),
        logit(p) <- a_actor[actor] + a_block[block_id] + (bp + bpc*condition) * prosoc_left,
        a_actor[actor] ~ dnorm(alpha, sigma_actor),
        a_block[block_id] ~ dnorm(gamma, sigma_block),
        c(alpha, gamma, bp, bpc) ~ dnorm(0, 10),
        c(sigma_actor, sigma_block) ~ dcauchy(0,1)
    ), data=d, warmup=1000, iter=6000, chains=4, cores=4)

precis(m12.4)

compare(m12.4.chapter, m12.4)

#+END_SRC

#+RESULTS:

#+BEGIN_SRC R :results graphics :file 12m4.png

par(mfrow=c(1,2))

plot(precis(m12.4, depth=2))
plot(precis(m12.4.chapter, depth=2))


#+END_SRC

#+RESULTS:
[[file:12m4.png]]

Second model trains very slowly. Rhat is higher for all coefficients. Bad convergence. 
In chapter model, alpha_actor and alpha_block is relative to alpha. Sigma is learned for
two alpha using HalfCauchy. 

1. District: ID number of administrative district each woman resided interaction
2. use.contraception: an indicator (0/1) of whether the woman was using contraception
3. urban: an indicator(0/1) of whether the woman lived in a city, as opposed to living in
   a rural area. 

** 12H1

#+BEGIN_SRC R :results output
library(rethinking)
data(bangladesh)
d <- bangladesh

sort(unique(d$district))

d$district_id <- as.integer(as.factor(d$district))
sort(unique(d$district_id))
d$use_contraception <- d$use.contraception

#+END_SRC

#+RESULTS:
: 
:  [1]  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25
: [26] 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50
: [51] 51 52 53 55 56 57 58 59 60 61
: 
:  [1]  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25
: [26] 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50
: [51] 51 52 53 54 55 56 57 58 59 60

#+BEGIN_SRC R 

m12h1.fixed <- map2stan(
    alist(
        use_contraception ~ dbinom(1, p),
        logit(p) <- a_district[district_id],
        a_district[district_id] ~ dnorm(0, 10)
        ), data=d, iter=4000, chains=4, cores=4)


m12h1.multi <- map2stan(
    alist(
        use_contraception ~ dbinom(1, p),
        logit(p) <- a_district[district_id],
        a_district[district_id] ~ dnorm(a, sigma),
        a ~ dnorm(0, 10),
        sigma ~ dcauchy(0, 1)
    ), data=d, iter=4000, chains=4, cores=4) 

#+END_SRC

#+RESULTS:

#+BEGIN_SRC R :results output
precis(m12h1.fixed, depth=2)
precis(m12h1.multi, depth=2)
compare(m12h1.fixed, m12h1.multi)
#+END_SRC

#+RESULTS:
#+begin_example
                Mean StdDev lower 0.89 upper 0.89 n_eff Rhat
a_district[1]  -1.08   0.21      -1.42      -0.75 14091    1
a_district[2]  -0.65   0.47      -1.37       0.11 15170    1
a_district[3]   4.41   3.06      -0.10       9.07  7941    1
a_district[4]   0.00   0.37      -0.59       0.59 16692    1
a_district[5]  -0.59   0.34      -1.16      -0.07 15046    1
a_district[6]  -0.90   0.27      -1.34      -0.46 14099    1
a_district[7]  -1.01   0.54      -1.85      -0.16 12051    1
a_district[8]  -0.51   0.34      -1.05       0.04 13923    1
a_district[9]  -0.86   0.48      -1.61      -0.12 14414    1
a_district[10] -2.81   1.16      -4.49      -0.99  8571    1
a_district[11] -6.25   2.63     -10.03      -2.37  5416    1
a_district[12] -0.66   0.39      -1.32      -0.08 14628    1
a_district[13] -0.35   0.43      -1.03       0.33 15084    1
a_district[14]  0.52   0.19       0.22       0.83 14516    1
a_district[15] -0.58   0.45      -1.31       0.13 14532    1
a_district[16]  0.21   0.46      -0.50       0.93 13503    1
a_district[17] -0.93   0.46      -1.65      -0.19 12980    1
a_district[18] -0.67   0.32      -1.15      -0.14 13931    1
a_district[19] -0.49   0.41      -1.17       0.15 13010    1
a_district[20] -0.43   0.54      -1.28       0.45 14652    1
a_district[21] -0.47   0.50      -1.27       0.32 15067    1
a_district[22] -1.47   0.59      -2.37      -0.51 11386    1
a_district[23] -1.08   0.62      -2.06      -0.13 12228    1
a_district[24] -2.89   1.16      -4.63      -1.09  7540    1
a_district[25] -0.21   0.25      -0.62       0.17 14483    1
a_district[26] -0.50   0.59      -1.42       0.43 12383    1
a_district[27] -1.54   0.40      -2.16      -0.90 13644    1
a_district[28] -1.15   0.33      -1.64      -0.60 12794    1
a_district[29] -0.97   0.40      -1.61      -0.33 14090    1
a_district[30] -0.03   0.27      -0.44       0.40 13140    1
a_district[31] -0.19   0.36      -0.76       0.38 14072    1
a_district[32] -1.40   0.52      -2.20      -0.56 11377    1
a_district[33] -0.31   0.56      -1.19       0.58 12961    1
a_district[34]  0.67   0.36       0.09       1.22 13812    1
a_district[35]  0.00   0.29      -0.45       0.48 13703    1
a_district[36] -0.65   0.53      -1.46       0.21 13857    1
a_district[37]  0.16   0.57      -0.73       1.10 14215    1
a_district[38] -0.97   0.60      -1.92      -0.02 14074    1
a_district[39]  0.01   0.40      -0.65       0.62 12994    1
a_district[40] -0.15   0.32      -0.65       0.36 13891    1
a_district[41]  0.00   0.40      -0.61       0.67 12391    1
a_district[42]  0.20   0.63      -0.82       1.19 15267    1
a_district[43]  0.14   0.30      -0.36       0.61 13583    1
a_district[44] -1.30   0.48      -2.05      -0.53 14227    1
a_district[45] -0.71   0.35      -1.26      -0.15 13781    1
a_district[46]  0.09   0.21      -0.25       0.43 13476    1
a_district[47] -0.15   0.53      -0.99       0.70 15631    1
a_district[48]  0.10   0.31      -0.40       0.60 14838    1
a_district[49] -5.01   2.94      -9.31      -0.57  6643    1
a_district[50] -0.11   0.47      -0.83       0.70 14115    1
a_district[51] -0.16   0.33      -0.70       0.36 13824    1
a_district[52] -0.23   0.25      -0.64       0.18 12967    1
a_district[53] -0.34   0.47      -1.06       0.42 15682    1
a_district[54] -1.93   1.24      -3.70       0.08  9024    1
a_district[55]  0.32   0.30      -0.16       0.79 13285    1
a_district[56] -1.55   0.51      -2.36      -0.73 14498    1
a_district[57] -0.18   0.36      -0.74       0.39 14237    1
a_district[58] -2.51   1.17      -4.16      -0.64  8512    1
a_district[59] -1.31   0.44      -2.01      -0.64 15507    1
a_district[60] -1.33   0.39      -1.95      -0.73 12031    1

       Mean StdDev lower 0.89 upper 0.89 n_eff Rhat
a[1]  -1.07   0.22      -1.41      -0.71   931 1.01
a[2]  -0.64   0.47      -1.37       0.11  1078 1.00
a[3]   4.42   2.99      -0.42       8.48  1102 1.00
a[4]   0.00   0.37      -0.57       0.60   901 1.00
a[5]  -0.60   0.35      -1.14      -0.02   980 1.00
a[6]  -0.89   0.28      -1.32      -0.43   859 1.00
a[7]  -1.03   0.55      -1.87      -0.15   769 1.00
a[8]  -0.52   0.35      -1.11       0.02   877 1.00
a[9]  -0.87   0.47      -1.59      -0.11  1004 1.00
a[10] -2.83   1.15      -4.57      -1.04   690 1.01
a[11] -6.19   2.52      -9.88      -2.34   878 1.01
a[12] -0.65   0.39      -1.25      -0.03  1059 1.00
a[13] -0.35   0.41      -1.03       0.25  1036 1.00
a[14]  0.52   0.19       0.19       0.81   952 1.00
a[15] -0.61   0.45      -1.31       0.13  1127 1.00
a[16]  0.19   0.46      -0.56       0.91   925 1.00
a[17] -0.93   0.44      -1.64      -0.22   954 1.01
a[18] -0.69   0.32      -1.19      -0.19  1002 1.00
a[19] -0.48   0.42      -1.12       0.20   907 1.00
a[20] -0.43   0.54      -1.32       0.42  1193 1.00
a[21] -0.45   0.49      -1.23       0.33  1121 1.00
a[22] -1.46   0.57      -2.38      -0.56   970 1.00
a[23] -1.07   0.60      -1.98      -0.09   907 1.00
a[24] -2.87   1.14      -4.53      -1.17   909 1.00
a[25] -0.21   0.25      -0.60       0.17  1038 1.00
a[26] -0.53   0.60      -1.48       0.42   878 1.00
a[27] -1.56   0.39      -2.20      -0.97   990 1.00
a[28] -1.14   0.31      -1.61      -0.62  1182 1.01
a[29] -0.98   0.39      -1.61      -0.37  1014 1.00
a[30] -0.04   0.26      -0.46       0.38  1058 1.01
a[31] -0.18   0.36      -0.78       0.37   952 1.00
a[32] -1.38   0.52      -2.17      -0.53  1100 1.00
a[33] -0.33   0.56      -1.17       0.59  1207 1.00
a[34]  0.66   0.36       0.10       1.24  1019 1.00
a[35]  0.02   0.29      -0.45       0.47  1048 1.00
a[36] -0.65   0.52      -1.45       0.21   976 1.00
a[37]  0.18   0.56      -0.77       1.05  1250 1.00
a[38] -0.98   0.61      -1.97      -0.05   802 1.00
a[39]  0.00   0.40      -0.60       0.66   966 1.00
a[40] -0.16   0.31      -0.61       0.38   994 1.01
a[41] -0.01   0.40      -0.62       0.64  1161 1.00
a[42]  0.16   0.63      -0.82       1.15  1128 1.01
a[43]  0.14   0.31      -0.38       0.60  1053 1.00
a[44] -1.32   0.48      -2.03      -0.50   938 1.00
a[45] -0.70   0.34      -1.25      -0.18  1108 1.00
a[46]  0.09   0.22      -0.27       0.44   973 1.01
a[47] -0.18   0.55      -1.10       0.66   993 1.00
a[48]  0.10   0.31      -0.37       0.61   986 1.01
a[49] -4.99   2.79      -9.17      -0.70   860 1.00
a[50] -0.12   0.47      -0.86       0.63  1018 1.00
a[51] -0.17   0.33      -0.65       0.37  1086 1.00
a[52] -0.24   0.27      -0.67       0.17   973 1.00
a[53] -0.33   0.47      -1.10       0.39  1201 1.00
a[54] -1.82   1.18      -3.68      -0.03  1011 1.01
a[55]  0.32   0.31      -0.19       0.80  1037 1.00
a[56] -1.55   0.53      -2.34      -0.71   859 1.01
a[57] -0.20   0.36      -0.81       0.36   951 1.00
a[58] -2.51   1.16      -4.22      -0.73  1178 1.01
a[59] -1.31   0.43      -2.01      -0.63  1249 1.00
a[60] -1.34   0.39      -1.96      -0.72  1032 1.00
sigma  0.00   0.00       0.00       0.00   NaN  NaN
Warning message:
In precis(m12h1.multi, depth = 2) :
  There were 7520 divergent iterations during sampling.
Check the chains (trace plots, n_eff, Rhat) carefully to ensure they are valid.

              WAIC pWAIC dWAIC weight    SE  dSE
m12h1.multi 2531.7  61.4   0.0   0.58 32.31   NA
m12h1.fixed 2532.3  61.7   0.6   0.42 32.37 0.72
#+end_example

#+BEGIN_SRC R :results graphics :file 12h1.png :width 800


link.fixed <- link(m12h1.fixed, data=data.frame(district_id=1:60))
mu.fixed <- apply(link.fixed, 2, mean)
PI.fixed <- apply(link.fixed, 2, PI)

link.multi <- link(m12h1.multi, data=data.frame(district_id=1:60))
mu.multi <- apply(link.multi, 2, mean)
PI.multi <- apply(link.multi, 2, PI)

library(dplyr)
d_sum <- d %>% as.tbl %>% group_by(district_id) %>% summarize(p_use_contraception=mean(use.contraception))

plot(y=d_sum$p_use_contraception, x=d_sum$district_id, pch=16, xlab="districts", ylab="proportion use_contraception")
abline(h=median(d_sum$p_use_contraception), lty=2)

points(y=mu.fixed, x=1:60, col='red')
points(y=mu.multi, x=(1:60)+0.3, col="green")

legend("topright",legend=c("raw data", 'fixed', 'multi'), fill=c('black', 'red', 'green'))

#+END_SRC

#+RESULTS:
[[file:12h1.png]]

** 12H2
#+BEGIN_SRC R 
library(rethinking)
data(Trolley)
d <- Trolley


m12h2 <- map2stan(
    alist(
        response ~ dordlogit( phi , cutpoints),
        phi <- bA*action + bI*intention + bC*contact,
        c(bA,bI,bC) ~ dnorm(0,10),
        cutpoints ~ dnorm(0, 10)
), 
data=d , iter=4000, chains=4, cores=4, start=list(cutpoints=c(-1.9,-1.2,-0.7,0.2,0.9,1.8)))

#+END_SRC

#+RESULTS:

#+BEGIN_SRC R 
d$id_ <- as.integer(d$id)


m12h2.multi <- map2stan(
     alist(
         response ~ dordlogit( phi , cutpoints) ,
         phi <- a_person[id_]+ bA*action + bI*intention + bC*contact,
         c(bA,bI,bC) ~ dnorm(0,10),
         cutpoints ~ dnorm(0,10),
         a_person[id_] ~ dnorm(0, sigma),
         sigma ~ dcauchy(0, 1)
), data=d, iter=4000, chains=4, cores=4, start=list(cutpoints=c(-1.9,-1.2,-0.7,0.2,0.9,1.8)))



#+END_SRC

#+RESULTS:

#+BEGIN_SRC R :results ouput
compare(m12h2, m12h2.multi)

#+END_SRC

#+BEGIN_SRC R
d.pred <- list(
    action = c(0, 1, 0, 1),
    intention = c(0, 0, 1, 1),
    contact = c(1,0,1,0),
    id_ = rep(2,4))

post <- extract.samples(m12h2.multi)
a_actor_sims <- rnorm(7000, 0, post$sigma)
a_actor_sims <- matrix(a_actor_sims, 1000, 7)

linkm12h2 <- link(m12h2.multi, n=1000, data=d.pred,
                  replace=list(a_person=a_actor_sims))

#+END_SRC

#+RESULTS:

#+BEGIN_SRC R

m12h2.multi <- map2stan(
     alist(
         response ~ dordlogit( phi , cutpoints) ,
         phi <- a_person[id_]+ a_story[story]+ bA*action + bI*intention + bC*contact,
         c(bA,bI,bC) ~ dnorm(0,10),
         cutpoints ~ dnorm(0,10),
         a_person[id_] ~ dnorm(0, sigma_person),
         a_story[story] ~ dnorm(0, sigma_story),
         sigma_person ~ dcauchy(0, 1),
         sigma_story ~ dcauchy(0, 1)
), data=d, iter=4000, chains=4, cores=4, start=list(cutpoints=c(-1.9,-1.2,-0.7,0.2,0.9,1.8)))


#+END_SRC

#+RESULTS:
